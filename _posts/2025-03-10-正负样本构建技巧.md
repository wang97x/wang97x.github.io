---
layout: post
title: "正负样本构建技巧"
author: "wang"
date: 2025-03-10 09:25:00 +0800
categories: [SentenceTransformers]
tags: [Dataset, 正负样本]
math: true
---
在信息检索和对比学习任务中，正负样本的构建质量直接影响模型性能。以下是针对科学文献检索场景的正负样本构建高级技巧，结合sciFact数据集特点的详细说明：

---

### **一、基础构建原则**
#### 1. 显式正样本（Positive Samples）
- **定义**：与声明（claim）存在明确支持关系的摘要
- **sciFact处理技巧**：
  ```python
  # 从标注数据中提取SUPPORT标签的证据
  positives = [ev["sentences"][0] for ev in claim_data if ev["label"] == "SUPPORT"]
  ```
- **注意事项**：
  - 处理多句证据时进行合理拼接
  - 验证摘要与声明的语义一致性（避免标注噪声）

#### 2. 显式负样本（Explicit Negative）
- **定义**：标注为CONTRADICT/NEUTRAL的摘要
- **构建策略**：
  ```python
  negatives = [ev["sentences"][0] for ev in claim_data 
              if ev["label"] in ["CONTRADICT", "NEUTRAL"]]
  ```
- **增强技巧**：
  - 对同一文献中的非相关段落进行采样
  - 跨文献采样相似主题但无关内容

---

### **二、高级构建技巧**
#### 1. 难负样本挖掘（Hard Negative Mining）
**策略**：
- **静态挖掘**（预计算）：
  ```python
  from sentence_transformers.util import semantic_search
  
  # 使用基础模型检索高相似度但非相关的样本
  query_embedding = base_model.encode(claim)
  corpus_embeddings = base_model.encode(all_abstracts)
  hits = semantic_search(query_embedding, corpus_embeddings, top_k=50)
  
  hard_negatives = [hit for hit in hits 
                   if hit['corpus_id'] not in gold_positives]
  ```
  
- **动态挖掘**（训练过程中）：
  ```python
  # 在训练过程中定期更新难负样本池
  if global_step % update_interval == 0:
      current_model.eval()
      with torch.no_grad():
          # 重新计算相似度并更新负样本
          new_hard_negs = find_hard_negatives(current_model)
      train_dataset.update_negatives(new_hard_negs)
  ```

#### 2. 批内负采样（In-batch Negative）
**实现方式**：
```python
# 使用MultipleNegativesRankingLoss自动利用批内负样本
train_loss = losses.MultipleNegativesRankingLoss(model)
```
**数学原理**：
- 对于批次中的每个正样本对 (q, p)，同一批次的其他文档作为负样本
- 损失函数：$-\log \frac{e^{s(q,p)}}{\sum_{n \in \text{batch}} e^{s(q,n)}}$

#### 3. 合成负样本（Synthetic Negative）
**生成方法**：
- **文本扰动**：
  ```python
  from nlpaug import Augmenter
  
  aug = Augmenter().char.random_delete(0.3)
  synthetic_neg = aug.augment(positive_text)
  ```
  
- **语义反转**：
  ```python
  # 使用文本生成模型创建矛盾陈述
  contradiction = model.generate(
      input_text=f"Generate a contradictory statement to: {claim}",
      max_length=128
  )
  ```

#### 4. 多粒度负样本

| 类型      | 示例                                               | 训练作用     |
|---------|--------------------------------------------------|----------|
| 字面相似负样本 | 相同术语不同上下文（"cell growth" vs "cancer cell growth"） | 提升语义区分能力 |
| 主题相关负样本 | 同一研究领域的不同结论                                      | 增强推理能力   |
| 对抗性负样本  | 仅修改关键词的欺骗性文本                                     | 提升鲁棒性    |

---

### **三、sciFact数据集特化技巧**
#### 1. 部分相关处理
- **分级标签**：
  ```python
  # 对部分相关样本进行加权
  if evidence["label"] == "PARTIALLY_SUPPORT":
      weight = 0.7  # 小于完全正样本的权重
  ```

#### 2. 文献元数据利用
```python
# 使用论文的以下特征增强负样本：
bad_negatives = [
    abstract for abstract in corpus 
    if (paper.publish_year < 2010) and  # 时间不相关
       (paper.domain != target_domain)  # 领域不相关
]
```

#### 3. 结构化信息融合
```python
# 构建包含图表信息的负样本
table_neg = f"As shown in Table 1: {table_description}"
figure_neg = f"Figure 3 demonstrates: {figure_caption}"
```

---

### **四、质量保障策略**
#### 1. 样本平衡控制
```python
# 动态调整正负样本比例
def dynamic_sampling_ratio(epoch):
    base_ratio = 1:3  # 初始正负比
    return base_ratio * (1 + epoch*0.2)  # 逐步增加负样本难度
```

#### 2. 噪声过滤
```python
# 使用规则过滤低质量样本
if len(abstract.split()) < 10:  # 过滤过短文本
    continue
if "[RETRACTED]" in abstract:   # 过滤撤回论文
    continue
```

#### 3. 可视化验证
```python
# 使用UMAP可视化样本分布
from umap import UMAP

umap = UMAP()
embeddings = model.encode(all_texts)
reduced = umap.fit_transform(embeddings)
plot_clusters(reduced, labels)
```

---

### **五、最佳实践组合策略**
```python
# 综合应用多种技巧的示例流程
def build_training_samples(claim_data):
    samples = []
    
    # 显式正样本
    for pos in claim_data["SUPPORT"]:
        samples.append(InputExample(texts=[claim, pos], label=1.0))
    
    # 硬负样本
    for hard_neg in mine_hard_negatives(claim):
        samples.append(InputExample(texts=[claim, hard_neg], label=0.0))
    
    # 合成负样本
    for syn_neg in generate_synthetic_negs(claim):
        samples.append(InputExample(texts=[claim, syn_neg], label=0.0))
    
    # 批内负采样自动处理
    return samples

# 训练时组合损失函数
final_loss = (
    0.6 * losses.MultipleNegativesRankingLoss(model) + 
    0.3 * losses.ContrastiveLoss(model) +
    0.1 * losses.CosineSimilarityLoss(model)
)
```

---

### **六、评估样本质量指标**
1. **正样本指标**：
   - 语义相似度（应显著高于负样本）
   - 主题一致性（使用LDA主题模型验证）

2. **负样本指标**：
   - 难易程度分布（相似度直方图）
   - 多样性熵值（基于嵌入向量的聚类分析）

3. **动态监控**：
   ```python
   # 在训练过程中监控样本质量
   def on_log(self, args, state, control, logs=None):
       if state.epoch % 1 == 0:
           analyze_hard_neg_quality(model, current_neg_pool)
           visualize_embedding_space(dev_samples)
   ```

---

### **七、领域适应技巧**
#### 1. 跨领域负采样
```python
# 加入其他科学领域的负样本
biology_negs = load_external_abstracts("biology")
physics_negs = load_external_abstracts("physics")
```

#### 2. 课程学习策略
```python
# 分阶段训练计划
training_schedule = [
    {"epochs": 2, "neg_type": "easy"},      # 初期使用简单负样本
    {"epochs": 3, "neg_type": "medium"},    # 中期中等难度
    {"epochs": 2, "neg_type": "hard"}       # 后期困难负样本
]
```

#### 3. 主动学习框架
```python
# 交互式样本优化循环
for iteration in range(3):
    model.train()
    uncertain_samples = find_ambiguous_samples(val_set)
    human_annotate(uncertain_samples)
    update_training_set(new_annotations)
```

---

通过综合运用这些技巧，可以显著提升检索模型的以下能力：
1. 区分语义细微差异的能力
2. 处理长尾分布问题的鲁棒性
3. 对对抗样本的抵抗能力
4. 跨领域泛化性能

实际应用中建议：
1. 从基础策略开始，逐步引入高级技巧
2. 持续监控样本质量分布
3. 定期进行人工样本审核
4. 根据验证集表现调整采样策略
