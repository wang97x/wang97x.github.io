---
layout: post 
title: "DeepSeek系列"
author: "wang"
date: 2025-02-12 13:14:00 +0800
categories: [LLM]
tags: [Deepseek]
---
## DeepSeek-R1-Zero、DeepSeek-R1 和 DeepSeek-V3-Base 之间的关系如下：

### DeepSeek-V3-Base
**基础模型**：DeepSeek-V3-Base 是 DeepSeek 系列模型的基础版本，具有 6710 亿参数，每次推理激活 370 亿参数。它在 14.8 万亿 tokens 上进行了预训练，采用混合专家（MoE）架构。  
**作用**：作为 DeepSeek-R1-Zero 和 DeepSeek-R1 的起点，为后续模型提供了强大的基础架构和预训练能力。

### DeepSeek-R1-Zero
**训练方式**：DeepSeek-R1-Zero 是在 DeepSeek-V3-Base 的基础上，通过纯粹的强化学习（RL）进行训练，不依赖监督微调（SFT）。它通过 GRPO（Group Relative Policy Optimization）算法进行高效 RL 训练。  
**特点**：展现了强大的推理能力，如自我验证、反思和生成长推理链（CoT），但在可读性、语言混合等方面存在问题。  
**性能**：在 AIME 2024 等基准测试中表现优异，Pass@1 成绩从 15.6% 提升至 71.0%，多数投票后达到 86.7%。

### DeepSeek-R1
**训练方式**：DeepSeek-R1 在 DeepSeek-R1-Zero 的基础上引入了冷启动数据进行监督微调（SFT），并结合多阶段训练。具体包括：
- **冷启动阶段**：使用高质量数据初始化模型，提升可读性和语言一致性。
- **强化学习阶段**：在冷启动微调后的模型上继续进行推理导向的强化学习。
- **拒绝采样与监督微调**：筛选高质量样本，进一步优化模型。
- **全场景强化学习**：对齐人类偏好，覆盖通用任务。

**特点**：解决了 DeepSeek-R1-Zero 的可读性和语言混合问题，同时保持强大的推理能力。  
**性能**：在多项推理基准测试中表现与 OpenAI-o1-1217 相当，甚至在某些任务上超越。

## 总结
- **DeepSeek-V3-Base**：基础模型，为后续模型提供了强大的预训练能力。
- **DeepSeek-R1-Zero**：通过纯粹的强化学习在推理能力上取得了突破，但存在一些问题。
- **DeepSeek-R1**：在 R1-Zero 的基础上引入冷启动数据和多阶段训练，解决了 R1-Zero 的问题，并进一步提升了性能。
